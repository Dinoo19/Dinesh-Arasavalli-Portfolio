<!DOCTYPE HTML>
<html>
  <head>
    <title>Experience | Dinesh Arasavalli</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
  </head>
  <body class="is-preload">

    <!-- Wrapper -->
    <div id="wrapper">

      <!-- Header -->
      <header id="header">
        <a href="index.html" class="logo"><strong>Dinesh Arasavalli</strong> <span>Portfolio</span></a>
        <nav>
          <a href="#menu">Menu</a>
        </nav>
      </header>

      <!-- Menu -->
      <nav id="menu">
        <ul class="links">
          <li><a href="index.html">Home</a></li>
          <li><a href="education.html">Education</a></li>
          <li><a href="experience.html">Experience</a></li>
          <li><a href="projects.html">Projects</a></li>
        </ul>
      </nav>

      <!-- Main -->
      <div id="main" class="alt">
        <section id="one">
          <div class="inner">
            <header class="major">
              <h1>Professional Experience</h1>
            </header>

            <!-- Experience 1 -->
            <section>
              <header class="major">
                <h2>Data Engineer — Goldman Sachs</h2>
                <p><strong>June 2024 – Present</strong></p>
              </header>
              <ul>
                <li>Designed real-time fraud pipelines using Apache Airflow, Pub/Sub, and BigQuery, processing 5–8M transactions per day and enabling sub-second scoring for high-risk activity.</li>
                <li>Engineered feature processing workflows in PySpark and Python, supporting low-latency inference and improving fraud alert precision across streaming data.</li>
                <li>Developed and deployed fraud detection models using Scikit-learn and XGBoost, reducing false positives by ~20% while meeting regulatory precision thresholds.</li>
                <li>Automated model training, validation, and deployment pipelines with Vertex AI and MLflow, standardizing reproducible workflows and reducing manual release effort.</li>
                <li>Implemented explainability frameworks using SHAP and LIME to support audit, compliance, and internal risk governance requirements.</li>
                <li>Designed monitoring and drift detection pipelines with cloud monitoring and MLflow tracking to maintain over 99% uptime for real-time scoring infrastructure.</li>
                <li>Built internal APIs and dashboards using FastAPI and Tableau to expose risk metrics, anomaly trends, and model outputs to fraud operations teams.</li>
                <li><strong>Environment:</strong> Python, SQL, Airflow, PySpark, BigQuery, Vertex AI, MLflow, Docker, FastAPI, Tableau</li>
              </ul>
            </section>

            <hr class="major" />

            <!-- Experience 2 -->
            <section>
              <header class="major">
                <h2>Data Scientist — Toyota</h2>
                <p><strong>June 2020 – July 2023 | India</strong></p>
              </header>
              <ul>
                <li>Architected analytics pipelines using Apache Airflow, Dataflow, and BigQuery, processing 8–12M operational records per day for forecasting and KPI reporting.</li>
                <li>Engineered feature pipelines with Python, PySpark, and SQL, generating 120+ time-series features for operational decision models.</li>
                <li>Built forecasting models using Prophet, LSTM, and XGBoost, improving planning accuracy by ~15% in scheduling workflows.</li>
                <li>Developed NLP pipelines with Hugging Face Transformers (BERT), automating classification of 50K+ monthly feedback records and reducing manual review.</li>
                <li>Implemented anomaly detection systems using Isolation Forest and Autoencoders, monitoring 20+ operational KPIs and identifying irregular patterns.</li>
                <li>Deployed production ML services with Vertex AI, Docker, and MLflow, ensuring consistent model performance across environments.</li>
                <li>Designed executive dashboards using Tableau and Looker Studio to translate model outputs into operational insights.</li>
                <li><strong>Environment:</strong> Python, SQL, PySpark, Airflow, TensorFlow, Scikit-learn, BigQuery, Vertex AI, Docker, MLflow, Tableau</li>
              </ul>
            </section>

            <hr class="major" />

            <div class="inner">
              <p><strong>Explore my projects:</strong> Check out my latest GitHub and machine learning work <a href="projects.html">here</a>.</p>
            </div>

          </div>
        </section>
      </div>

      <!-- Footer -->
      <footer id="footer">
        <div class="inner">
          <ul class="icons">
            <li><a href="https://github.com/Dinoo19" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
            <li><a href="https://www.linkedin.com/in/dinesh-arasavalli" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
          </ul>
          <ul class="copyright">
            <li>&copy; 2025 Dinesh Arasavalli</li><li>Design by <a href="https://html5up.net">HTML5 UP</a></li>
          </ul>
        </div>
      </footer>

    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>

  </body>
</html>
